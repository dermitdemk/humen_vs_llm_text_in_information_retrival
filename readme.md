# Evaluating Information Retrieval Performance on Human-written and AI-generated News Articles

#### _AIR - WS2025 - Group 07_

|                       |                    |                              |
| :-------------------: | :----------------: | :--------------------------: |
|     **Erik Koppenhagen**    | **Simon Fessl** |     **Jasmin Bauer**     |
| Dataset, Preprocessing |      Methods/Models     | Evaluation |

In the recent years, the use of large language models (LLMs) has led to a rapid increase of AI-
generated content on the internet. Specifically in journalism the use of AI also increased.
The texts of news articles are revised, rewritten or sometimes even completely generated by AI. Thus, search engines and information retrieval systems are faced with the challenge of jointly indexing and evaluating both human-written and fully AI-generated texts according to their relevance. This raises the important question, whether traditional and neural information retrieval models process both types of text equally well, or whether systematic differences occur regarding the retrieval quality. Exactly in this growing relevance of mixed corpora of human- and AI-generated news articles lies the motivation for this project. Because the information systems have to ensure that relevant content is reliably found and ranked correctly according to its relevance, regardless of its origin. But AI-generated text exhibits some different linguistic and semantic properties in comparison to human-written text and this could affect the effectiveness of existing information retrieval models and lead to a bias in the search results, namely that AI-generated news articles are preferentially retrieved. Because of this, this project pursues to answer the following research question: â€How do completely AI-generated news articles influence the retrieval effectiveness of traditional and neural information retrieval models?â€

## Code structure 

#### Data scraping and prepocessing
- get_tageschau_links.ipynb -> creates a list of links to all Tageschau articles of the past 2 years and saves the articles as JSON.
- tageschau_paster.ipynb -> parses the JSON files and extracts the important parts of the articles.
#### Generating LLM Text
- bullets.py -> uses LLM to summarize the article text in a list of bullet points
- bullets_to_text.py -> uses LLM to write a news article based on the bullet points
#### Information retrieval and evaluation
- information_retrival_pipeline.py -> retrieves top k articles with BM25 and bi-encoder
- run information_retrteval_pipeline.ipynb -> evaluates results and plots data.
